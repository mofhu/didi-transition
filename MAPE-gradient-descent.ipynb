{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [ 8]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [12]\n",
      " [ 7]\n",
      " [ 6]\n",
      " [14]\n",
      " [ 8]\n",
      " [11]\n",
      " [ 9]\n",
      " [30]\n",
      " [12]\n",
      " [ 8]]\n",
      "[  9.   6.  10.   8.   9.   5.  12.  11.  11.   9.   9.  13.   8.  32.  19.\n",
      "   9.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for dist in range(1, 67):\\n    cal_dist(dist)\\n    #print(cv_real_all, cv_pred_all)\\n    print(len(cv_real_all))\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "import math\n",
    "\n",
    "\n",
    "def MAPE_scorer(y, y_pred):\n",
    "    error = 0\n",
    "    num = len(y)\n",
    "    for i in range(0, num):\n",
    "        if y[i] > 0:\n",
    "            error += math.fabs(y_pred[i] - y[i]) / y[i]\n",
    "    #print('error, num:', error, num)\n",
    "    if num > 0:\n",
    "        return error / num\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "my_scorer = make_scorer(MAPE_scorer)\n",
    "# y = df['gap'][:21*66*144]\n",
    "# MAPE_scorer(y, [1 for i in range(0, 21*66*144)])\n",
    "\n",
    "\n",
    "def cal_dist(dist):\n",
    "    global cv_pred_all, cv_real_all\n",
    "    # split training, CV, test set\n",
    "    df = pd.read_csv(\"data/season_1/features/\"+ str(dist)+\".csv\")\n",
    "\n",
    "    df[\"date\"] = df[\"date\"].apply(lambda x: pd.to_datetime(x, errors='coerce'))\n",
    "\n",
    "    training = df.loc[(df.date < '2016-01-17') | (df.date == '2016-01-18')]\n",
    "\n",
    "    training_time = training.loc[df.time_slice.isin([46, 58, 70, 82, 94, 106, 118, 130, 142])]\n",
    "\n",
    "    cv = df.loc[df['date'].isin(['2016-01-17','2016-01-19','2016-01-20',\n",
    "                                '2016-01-21'])]\n",
    "\n",
    "    cv_time = cv.loc[df.time_slice.isin([46, 58, 70, 82, 94, 106, 118, 130, 142])]\n",
    "    # only catch time slice in test set\n",
    "\n",
    "    test = df.loc[(df['date'].isin(['2016-01-23','2016-01-27','2016-01-31']) & df['time_slice'].isin([46, 58, 70, 82, 94, 106, 118, 130, 142]))\n",
    "        |\\\n",
    "        (df['date'].isin(['2016-01-25','2016-01-29']) &\\\n",
    "            df['time_slice'].isin([58, 70, 82, 94, 106, 118, 130, 142]))]\n",
    "\n",
    "    # In[126]:\n",
    "    def modifier(y_pred):\n",
    "        # print(y_pred)\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] < 1:\n",
    "                y_pred[i] = 1\n",
    "        #print(y_pred)\n",
    "        return y_pred\n",
    "    #modifier(list(y_training))\n",
    "\n",
    "    from sklearn import linear_model\n",
    "    y_test_all = []\n",
    "    #for time in [46, 58, 70, 82, 94, 106, 118, 130, 142]:\n",
    "    for time in [70]:\n",
    "        training_ts = training_time.loc[training_time.time_slice == time]\n",
    "        cv_ts = cv_time.loc[cv.time_slice == time]\n",
    "        test_ts = test.loc[test.time_slice == time]\n",
    "        X_training = training_ts.as_matrix(columns=[\n",
    "                                    # 'is_workday',\n",
    "                                    # 'gap_30min',\n",
    "                                    # 'gap_20min',\n",
    "                                    'gap_10min'])\n",
    "        y_training = training_ts.as_matrix(columns=['gap']).ravel()\n",
    "        X_cv = cv_ts.as_matrix(columns=[\n",
    "                                    # 'is_workday',\n",
    "                                    # 'gap_30min',\n",
    "                                    # 'gap_20min',\n",
    "                                    'gap_10min'])\n",
    "        y_cv = cv_ts.as_matrix(columns=['gap']).ravel()\n",
    "        X_test = test_ts.as_matrix(columns=[\n",
    "                                    # 'is_workday',\n",
    "                                    # 'gap_30min',\n",
    "                                    # 'gap_20min',\n",
    "                                    'gap_10min'])\n",
    "        print(X_training)\n",
    "        print(y_training)\n",
    "        return training_ts, y_training\n",
    "        \"\"\"\n",
    "        clf = linear_model.LinearRegression()\n",
    "        clf.fit(X_training, y_training)\n",
    "        #print(time, clf.score(X_training, y_training), clf.score(X_cv, y_cv),\n",
    "        #     (MAPE_scorer(y_cv, clf.predict(X_cv))))\n",
    "        #print(clf.coef_ ,clf.predict(X_test))\n",
    "        MAPE_train = MAPE_scorer(y_training, modifier(clf.predict(X_training)))\n",
    "        MAPE_cv = MAPE_scorer(y_cv, modifier(clf.predict(X_cv)))\n",
    "        MAPE_1_train = MAPE_scorer(y_training, [1 for x in range(len(y_training))])\n",
    "        MAPE_1_cv = MAPE_scorer(y_cv, [1 for x in range(len(y_cv))])\n",
    "        \"\"\"\"\"\"if MAPE_train > MAPE_1_train or MAPE_cv > MAPE_1_cv:\n",
    "            print('dist {}, time_slice {}: train {:.2}, cv {:.2}'.format(dist, time,\n",
    "                MAPE_train, MAPE_cv))\n",
    "            print('dist {}, time_slice {}: baseline {:.2}, {:.2}'.format(dist, time,\n",
    "                MAPE_1_train ,\n",
    "                MAPE_1_cv ))\n",
    "                \"\"\"\n",
    "        \"\"\"print(MAPE_cv, MAPE_1_cv)\n",
    "        if MAPE_train >= MAPE_1_train:\n",
    "            y_cv_pred = [1 for x in range(len(y_cv))]\n",
    "            y_test = [1 for x in range(X_test.shape[0])]\n",
    "        else:\n",
    "            y_test = modifier(clf.predict(X_test))\n",
    "            y_cv_pred = modifier(clf.predict(X_cv))\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #print(y_test)\n",
    "        #print(modifier(y_test))\n",
    "        cv_real_all += list(y_cv)\n",
    "        cv_pred_all += list(y_cv_pred)\n",
    "        y_test_all += list(y_test)\n",
    "\n",
    "    test = test.sort_values(by=['time_slice','date'])\n",
    "    test['y'] = y_test_all\n",
    "    \"\"\"\n",
    "    # test[['start_district_num','date','time_slice','y']].to_csv('pred' + str(dist) + '.csv')\n",
    "\n",
    "cv_real_all = []\n",
    "cv_pred_all = []\n",
    "\n",
    "training_ts, y_ts = cal_dist(51)\n",
    "\"\"\"for dist in range(1, 67):\n",
    "    cal_dist(dist)\n",
    "    #print(cv_real_all, cv_pred_all)\n",
    "    print(len(cv_real_all))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893863850422\n",
      "(0.79250800574785607, 1.2256316462204222)\n",
      "0.238298153498\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "iterations = 500\n",
    "alpha = 0.005\n",
    "\n",
    "## Add a columns of 1s as intercept to X. This becomes the 2nd column\n",
    "X_df = training_ts['gap_10min']\n",
    "\n",
    "X = np.ones((2, np.array(X_df).size))\n",
    "X[:-1,:] = np.array(X_df)\n",
    "#print(X_df)\n",
    "## Transform to Numpy arrays for easier matrix math\n",
    "## and start beta at 0, 0\n",
    "# X = np.array(X_df)\n",
    "y = y_ts.ravel()\n",
    "beta = np.array([0, 1])\n",
    "m, b = beta # m-slope, b-intercept\n",
    "\n",
    "def cost_function(X, y, beta):\n",
    "    \"\"\"\n",
    "    cost_function(X, y, beta) computes the cost of using beta as the\n",
    "    parameter for linear regression to fit the data points in X and y\n",
    "    \"\"\"\n",
    "    ## number of training examples\n",
    "    m = len(y)\n",
    "\n",
    "    J_MAPE = MAPE_scorer(y, X.T.dot(beta))  \n",
    "\n",
    "    return J_MAPE\n",
    "\n",
    "cost_function(X, y_ts,beta)\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    \"\"\"\n",
    "    gradient_descent() performs gradient descent to learn theta by\n",
    "    taking num_iters gradient steps with learning rate alpha\n",
    "    \"\"\"\n",
    "    cost_history = [0] * iterations\n",
    "    beta = theta\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        m,b = beta\n",
    "        beta0 = beta\n",
    "        cost0 = cost_function(X,y_ts,beta)\n",
    "        gm = 0\n",
    "        gb = 0\n",
    "        for i in range(X.shape[1]):\n",
    "            # cal gradient\n",
    "            xi = X[0,i]\n",
    "            yi = y[i]\n",
    "            #print(xi, yi)\n",
    "            gm += (2 * (xi**2) * m + 2 *xi *(b-yi)) / (yi**2)\n",
    "            gb += (2 * b + 2*(m *xi -yi)) / (yi**2)\n",
    "            #print(gm,gb)\n",
    "            \n",
    "            #g_m = 2 * X\n",
    "        beta = (m-gm*alpha, b-gb*alpha)\n",
    "        cost1 = cost_function(X,y_ts,beta)\n",
    "        if cost1 > cost0:\n",
    "            print('iter', iteration, cost0, cost1)\n",
    "            return beta0\n",
    "        # print(cost_function(X,y_ts,beta))\n",
    "        #break\n",
    "        '''\n",
    "        hypothesis = X.dot(beta)\n",
    "        loss = hypothesis-y\n",
    "        gradient = X.T.dot(loss)/m\n",
    "        beta = theta - alpha*gradient\n",
    "        cost = cost_function(X, y, beta)\n",
    "        cost_history[iteration] = cost\n",
    "        '''\n",
    "        ## If you really want to merge everything in one line:\n",
    "        # beta = theta - alpha * (X.T.dot(X.dot(beta)-y)/m)\n",
    "        # cost = cost_function(X, y, beta)\n",
    "        # cost_history[iteration] = cost\n",
    "\n",
    "    return beta# , cost_history\n",
    "print(cost_function(X, y_ts,beta))\n",
    "beta = gradient_descent(X, y, beta, alpha, iterations)\n",
    "print(beta)\n",
    "print(cost_function(X, y_ts,beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5   8 125  11  10   3   4   3   2 104  13   2   9  10  30  62   1]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.array(X_df))\n",
    "print(np.array(X_df).size)\n",
    "#np.ones(np.array(X_df).size)\n",
    "X_1 = np.ones((2, np.array(X_df).size))\n",
    "X_1[:-1,:] = np.array(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
